# HybridMind - Offline/Online AI Chatbot

A hybrid Android app that seamlessly switches between cloud-based Gemini AI and on-device MediaPipe LLM based on network connectivity.

## Features

- ğŸ”„ **Hybrid Intelligence**: Automatically switches between Gemini (online) and Gemma (offline)
- ğŸ” **Firebase Authentication**: Secure login with session persistence
- ğŸ’¾ **Offline-First**: Local Room database with smart sync strategy
- ğŸ”’ **Privacy Mode**: Offline messages never sync to cloud
- ğŸ§¹ **Auto-Cleanup**: Automatic pruning of old offline messages (90 days)
- ğŸ“± **Material3 UI**: Modern, Gemini-inspired interface

## Tech Stack

- **Language**: Kotlin
- **UI**: Jetpack Compose (Material3)
- **Online AI**: Google Generative AI SDK (gemini-1.5-flash)
- **Offline AI**: MediaPipe LLM Inference (Gemma 2B/4B)
- **Database**: Room
- **Auth**: Firebase Authentication
- **Background**: WorkManager
- **Architecture**: Repository Pattern with Flow

## Setup Instructions

### 1. Prerequisites
- Android Studio Hedgehog or later
- Android SDK 26+
- Firebase project

### 2. Firebase Setup
1. Create a Firebase project at [console.firebase.google.com](https://console.firebase.google.com)
2. Enable Firebase Authentication (Email/Password and Google Sign-In)
3. Download `google-services.json` and place it in `app/` directory

### 3. API Keys
1. Get a Gemini API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Open `MainActivity.kt` and replace `YOUR_GEMINI_API_KEY` with your actual key

### 4. Model Files
The app will prompt you to download a model on first run. For testing with real models:
- Update URLs in `DownloadScreen.kt` to point to actual Gemma model files
- Alternatively, manually place a `.bin` file in the app's files directory

### 5. Build & Run
```bash
./gradlew assembleDebug
```

## Project Structure

```
app/src/main/java/com/example/hybridmind/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ NetworkMonitor.kt          # Connectivity tracking
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ChatRepository.kt          # Hybrid routing logic
â”‚   â”œâ”€â”€ ModelDownloader.kt         # Model download manager
â”‚   â””â”€â”€ local/
â”‚       â””â”€â”€ AppDatabase.kt         # Room database
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ AuthScreen.kt          # Firebase login
â”‚   â”œâ”€â”€ download/
â”‚   â”‚   â””â”€â”€ DownloadScreen.kt      # Model selection
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â””â”€â”€ ChatScreen.kt          # Main chat interface
â”‚   â””â”€â”€ theme/
â”‚       â””â”€â”€ Theme.kt               # Material3 theming
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ AutoPruneWorker.kt         # Background cleanup
â””â”€â”€ MainActivity.kt                # App entry point
```

## Key Concepts

### Hybrid Router
The `ChatRepository` acts as the single source of truth, routing messages to either:
- **Online**: Gemini API + save to Room + sync to Firestore (future)
- **Offline**: MediaPipe LLM + save to Room with `is_offline_only=true` flag

### Privacy Rules
- Messages created while offline are marked as private
- They are **never synced** to the cloud, even when connectivity is restored
- Auto-pruned after 90 days to save space

### Memory Safety
- Checks available RAM before allowing 4GB model download
- MediaPipe initialized in background to avoid UI jank
- WakeLock during model downloads to prevent interruption

## TODO
- [ ] Add Firestore sync for online messages
- [ ] Implement multimodal support (image input)
- [ ] Add conversation export
- [ ] Implement streaming responses
- [ ] Add voice input

## License
MIT
